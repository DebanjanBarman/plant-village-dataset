{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78883f51-1e49-4373-9fb1-359c7d822bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "json_file_path = \"/Plant_Disease_Dataset_Unified\"\n",
    "print(os.path.exists(json_file_path))  # This should return True if the file exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba48b27-26de-4924-bd6c-959d01f56c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./venv/lib64/python3.12/site-packages (from opencv-python) (2.2.3)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae8ad05-f58f-4463-9c34-c8637bd265e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', 'Plant_Disease_Dataset_Unified', 'plant-image-identification-with-SAM.ipynb', '.ipynb_checkpoints', 'segment-anything', 'venv', 'requirements.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abcd519a-2527-4568-9974-0360b96c2d79",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Plant_Disease_Dataset_Unified/train/images/Apple___Apple_scab/0a5e9323-dbad-432d-ac58-d291718345d9___FREC_Scab 3417_90deg.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m     mask_image.save(mask_path)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mjson_to_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Plant_Disease_Dataset_Unified/train/images/Apple___Apple_scab/0a5e9323-dbad-432d-ac58-d291718345d9___FREC_Scab 3417_90deg.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Plant_Disease_Dataset_Unified/train/images/Apple___Apple_scab/masks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     42\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mjson_to_mask\u001b[39m\u001b[34m(json_file, output_dir)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjson_to_mask\u001b[39m(json_file, output_dir):\n\u001b[32m      8\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m    Convert LabelMe JSON annotations to binary masks.\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m    :param json_file: Path to the JSON annotation file.\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m    :param output_dir: Directory to save the generated mask.\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     14\u001b[39m         data = json.load(f)\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# Get image dimensions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/run/media/deba/4d5516aa-67e5-4502-be6f-4017f505dc0f/plant-village-dataset/venv/lib64/python3.12/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Plant_Disease_Dataset_Unified/train/images/Apple___Apple_scab/0a5e9323-dbad-432d-ac58-d291718345d9___FREC_Scab 3417_90deg.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def json_to_mask(json_file, output_dir):\n",
    "    \"\"\"\n",
    "    Convert LabelMe JSON annotations to binary masks.\n",
    "    :param json_file: Path to the JSON annotation file.\n",
    "    :param output_dir: Directory to save the generated mask.\n",
    "    \"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Get image dimensions\n",
    "    img_width = data['imageWidth']\n",
    "    img_height = data['imageHeight']\n",
    "    mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "\n",
    "    # Iterate over all annotated shapes (polygons)\n",
    "    for shape in data['shapes']:\n",
    "        points = np.array(shape['points'], dtype=np.int32)\n",
    "        label = shape['label'].lower()  # Ensure case-insensitive comparison\n",
    "\n",
    "        # Assign pixel values based on the label\n",
    "        if label == \"diseased\":  # Replace with your actual label name\n",
    "            cv2.fillPoly(mask, [points], 255)\n",
    "        else:\n",
    "            cv2.fillPoly(mask, [points], 0)  # Optional for multiple classes\n",
    "\n",
    "    # Save the mask as a PNG file\n",
    "    mask_filename = os.path.basename(json_file).replace('.json', '.png')\n",
    "    mask_path = os.path.join(output_dir, mask_filename)\n",
    "    mask_image = Image.fromarray(mask)\n",
    "    mask_image.save(mask_path)\n",
    "\n",
    "# Example usage\n",
    "json_to_mask(\n",
    "    json_file=\"/Plant_Disease_Dataset_Unified/train/images/Apple___Apple_scab/0a5e9323-dbad-432d-ac58-d291718345d9___FREC_Scab 3417_90deg.json\",\n",
    "    output_dir=\"/Plant_Disease_Dataset_Unified/train/images/Apple___Apple_scab/masks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88853b0-b878-48ea-8cd0-2c4935733102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e631e5-0737-47e4-b697-fb05b4d82779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4f849-ee8f-4705-acf0-71098d4968c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28263e-1c12-4185-969b-9f66016ca7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52335ec-8fcc-4229-a8e2-ba439aa341a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f773e9a-b15c-4127-b961-9299da30c3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.flake8', '.gitignore', 'CODE_OF_CONDUCT.md', 'CONTRIBUTING.md', 'LICENSE', 'README.md', 'assets', 'demo', 'linter.sh', 'notebooks', 'scripts', 'segment_anything', 'setup.cfg', 'setup.py', 'sam_vit_h_4b8939.pth', 'segment_anything.egg-info']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m sam_checkpoint = \u001b[33m\"\u001b[39m\u001b[33msegment-anything/sam_vit_h_4b8939.pth\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Path to SAM weights model_type = \"vit_h\"  # Use \"vit_b\" for smaller models\u001b[39;00m\n\u001b[32m     10\u001b[39m device = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m sam = sam_model_registry[\u001b[43mmodel_type\u001b[49m](checkpoint=sam_checkpoint)\n\u001b[32m     13\u001b[39m sam.to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'model_type' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(os.listdir(\"./segment-anything\"))\n",
    "from segment_anything import sam_model_registry\n",
    "\n",
    "# Load SAM model\n",
    "\n",
    "sam_checkpoint = \"segment-anything/sam_vit_h_4b8939.pth\"  # Path to SAM weights model_type = \"vit_h\"  # Use \"vit_b\" for smaller models\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6bffde-f942-4491-b719-b178a334cce7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "\n",
    "        # Load all image and mask paths\n",
    "        for class_name in os.listdir(root_dir):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                mask_path = img_path.replace(\"images\", \"masks\")  # Assuming masks are stored separately\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_paths.append(mask_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "    \n",
    "        # Load image and mask\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "    \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']  # Already a tensor due to ToTensorV2()\n",
    "            mask = augmented['mask']    # Already a tensor due to ToTensorV2()\n",
    "    \n",
    "        # Add channel dimension to mask\n",
    "        mask = mask.unsqueeze(0)  # Shape: (1, H, W)\n",
    "    \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a4f0387-293b-4031-81b0-cb820269379f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mA\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToTensorV2\n\u001b[1;32m      4\u001b[0m transform \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      5\u001b[0m     A\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m),  \u001b[38;5;66;03m# Resize to 256x256\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     A\u001b[38;5;241m.\u001b[39mHorizontalFlip(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     ToTensorV2(),\n\u001b[1;32m     10\u001b[0m ])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(256, 256),  # Resize to 256x256\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # ImageNet normalization\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "049ecbc4-e89d-48e4-ba6f-3ae096397c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define dataset paths\n",
    "train_dataset = PlantDiseaseDataset(root_dir=\"Plant_Disease_Dataset_Unified/train\", transform=transform)\n",
    "valid_dataset = PlantDiseaseDataset(root_dir=\"Plant_Disease_Dataset_Unified/valid\", transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e0aff34-8a28-4b66-af6a-597a2bfa06a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 256, 256])\n",
      "Mask shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "dataset = PlantDiseaseDataset(root_dir=\"Plant_Disease_Dataset_Unified/train\", transform=transform)\n",
    "image, mask = dataset[0]  # Get the first sample\n",
    "print(\"Image shape:\", image.shape)  # Should be (3, H, W)\n",
    "print(\"Mask shape:\", mask.shape)   # Should be (1, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51571681-3d89-4ff9-a35e-7504c3a35584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([8, 3, 256, 256])\n",
      "Masks shape: torch.Size([8, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for images, masks in train_loader:\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Masks shape:\", masks.shape)\n",
    "    break  # Stop after one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49428316-9f42-4113-8bf3-68e3525305c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load image at path: path/to/image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@871.622] global loadsave.cpp:268 findDecoder imread_('path/to/image.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def generate_mask(image_path, output_path):\n",
    "    # Load an image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Could not load image at path: {image_path}\")\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Initialize SAM predictor\n",
    "    predictor.set_image(image)\n",
    "\n",
    "    # Define a point prompt\n",
    "    input_point = np.array([[100, 100]])  # Point on diseased region\n",
    "    input_label = np.array([1])  # 1 for foreground\n",
    "\n",
    "    # Generate mask\n",
    "    masks, _, _ = predictor.predict(\n",
    "        point_coords=input_point,\n",
    "        point_labels=input_label,\n",
    "        multimask_output=True,  # Enable multi-mask output\n",
    "    )\n",
    "\n",
    "    # Save the mask\n",
    "    mask_image = Image.fromarray((masks[0] * 255).astype(np.uint8))\n",
    "    mask_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    generate_mask(\"path/to/image.jpg\", \"path/to/output/mask.png\")\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8beea-551b-40b0-8979-b750ae4d2b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
